<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Enterprise RAG System — AI Project Details</title>
  <link rel="stylesheet" href="../premium-style.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
  <style>
    .project-header {
      padding: 60px 0 40px;
      border-bottom: 1px solid var(--border);
    }
    .back-link {
      display: inline-flex;
      align-items: center;
      gap: 8px;
      color: var(--text-secondary);
      text-decoration: none;
      margin-bottom: 24px;
      font-weight: 500;
      transition: all 0.3s ease;
    }
    .back-link:hover {
      color: var(--primary);
      transform: translateX(-4px);
    }
    .project-title {
      font-size: 3rem;
      font-weight: 800;
      margin-bottom: 16px;
      background: linear-gradient(135deg, #fff, var(--primary));
      -webkit-background-clip: text;
      -webkit-text-fill-color: transparent;
      background-clip: text;
    }
    .project-meta {
      display: flex;
      gap: 24px;
      flex-wrap: wrap;
      margin-top: 24px;
      color: var(--text-secondary);
    }
    .project-meta span {
      display: flex;
      align-items: center;
      gap: 8px;
    }
    .tech-badges {
      display: flex;
      flex-wrap: wrap;
      gap: 12px;
      margin: 24px 0;
    }
    .badge {
      background: rgba(0, 212, 255, 0.1);
      border: 1px solid var(--primary);
      color: var(--primary);
      padding: 8px 16px;
      border-radius: 20px;
      font-size: 0.9rem;
      font-weight: 600;
    }
    .content-section {
      margin: 48px 0;
    }
    .content-section h3 {
      font-size: 1.8rem;
      margin-bottom: 20px;
      color: var(--text-primary);
    }
    .highlight-box {
      background: rgba(16, 185, 129, 0.1);
      border-left: 4px solid var(--success);
      padding: 20px;
      border-radius: 8px;
      margin: 24px 0;
    }
    .warning-box {
      background: rgba(249, 115, 22, 0.1);
      border-left: 4px solid var(--accent);
      padding: 20px;
      border-radius: 8px;
      margin: 24px 0;
    }
  </style>
</head>
<body>
  <div class="container">
    <div class="project-header">
      <a href="../index.html" class="back-link"><i class="fas fa-arrow-left"></i> Back to Portfolio</a>
      <h1 class="project-title"><i class="fas fa-robot"></i> Enterprise RAG System for Document Q&A</h1>
      <p style="font-size: 1.2rem; color: var(--text-secondary); max-width: 800px;">Intelligent retrieval-augmented generation system processing 10,000+ technical documents with semantic search and context-aware LLM responses.</p>
      
      <div class="project-meta">
        <span><i class="fas fa-calendar-alt"></i> Duration: 5 weeks</span>
        <span><i class="fas fa-book"></i> Domain: NLP & LLMs</span>
        <span><i class="fas fa-flag"></i> Type: Personal Project</span>
      </div>

    <div class="content-section">
      <h3><i class="fas fa-bullseye"></i> Project Overview</h3>
      <p>Built an enterprise-grade RAG (Retrieval-Augmented Generation) system that enables natural language querying over 10,000+ technical documents. Implemented intelligent document chunking, semantic search with vector embeddings, hybrid retrieval (dense + sparse), and prompt engineering for accurate, context-aware responses. Reduced query latency by 60% through optimization and achieved 85% answer accuracy on benchmark evaluation set.</p>
    </div>

    <div class="warning-box">
      <h3 style="color: var(--accent); margin-bottom: 12px;"><i class="fas fa-lightbulb"></i> Technical Challenges & Solutions</h3>
      <ul style="line-height: 2;">
        <li><strong>Challenge:</strong> Large document corpus causing slow retrieval → <strong>Solution:</strong> Implemented hierarchical indexing with Pinecone</li>
        <li><strong>Challenge:</strong> Context window limitations → <strong>Solution:</strong> Smart chunking with overlap and metadata tagging</li>
        <li><strong>Challenge:</strong> Irrelevant retrieved chunks → <strong>Solution:</strong> Hybrid search (dense + BM25) with reranking</li>
        <li><strong>Challenge:</strong> Hallucination in responses → <strong>Solution:</strong> Prompt engineering with cite-sources instructions</li>
        <li><strong>Challenge:</strong> High API costs → <strong>Solution:</strong> Caching layer and prompt optimization</li>
      </ul>
    </div>

    <div class="content-section">
      <h3><i class="fas fa-toolbox"></i> Tools & Technologies</h3>
      <div class="tech-badges">
        <span class="badge">LangChain</span>
        <span class="badge">Pinecone</span>
        <span class="badge">OpenAI GPT-4</span>
        <span class="badge">FastAPI</span>
        <span class="badge">Streamlit</span>
        <span class="badge">HuggingFace</span>
        <span class="badge">Redis</span>
        <span class="badge">Docker</span>
      </div>
    </div>

    <div class="content-section">
      <h3><i class="fas fa-project-diagram"></i> System Architecture</h3>
      <ol style="line-height: 2; color: var(--text-secondary);">
        <li><strong>Document Ingestion:</strong> PDF/Markdown parsing, cleaning, metadata extraction</li>
        <li><strong>Chunking Strategy:</strong> Recursive text splitting with 500-token chunks and 50-token overlap</li>
        <li><strong>Embedding Generation:</strong> OpenAI text-embedding-3-large for vector representations</li>
        <li><strong>Vector Storage:</strong> Pinecone index with metadata filtering capabilities</li>
        <li><strong>Hybrid Retrieval:</strong> Dense vector search + BM25 sparse retrieval combined with RRF</li>
        <li><strong>Reranking:</strong> Cross-encoder model for relevance scoring of retrieved chunks</li>
        <li><strong>LLM Generation:</strong> GPT-4 with carefully crafted prompts for context-aware answers</li>
        <li><strong>Caching Layer:</strong> Redis for frequently asked questions to reduce latency and cost</li>
      </ol>
    </div>

    <div class="content-section">
      <h3><i class="fas fa-star"></i> Key Features & Metrics</h3>
      <ul style="line-height: 2; color: var(--text-secondary);">
        <li><i class="fas fa-check" style="color: var(--success);"></i> <strong>85% answer accuracy</strong> on evaluation benchmark (500 Q&A pairs)</li>
        <li><i class="fas fa-check" style="color: var(--success);"></i> <strong>1.2s average response time</strong> (60% faster than initial baseline)</li>
        <li><i class="fas fa-check" style="color: var(--success);"></i> <strong>10,000+ documents</strong> indexed with semantic search</li>
        <li><i class="fas fa-check" style="color: var(--success);"></i> <strong>Hybrid retrieval</strong> improving recall by 25% over pure vector search</li>
        <li><i class="fas fa-check" style="color: var(--success);"></i> <strong>40% cost reduction</strong> through caching and prompt optimization</li>
      </ul>
    </div>

    <div class="highlight-box">
      <h3 style="color: var(--success); margin-bottom: 12px;"><i class="fas fa-trophy"></i> Project Outcome</h3>
      <p>Successfully deployed a production-ready RAG system that processes 500+ queries daily with high accuracy and low latency. The hybrid retrieval approach significantly improved answer quality, while the caching layer reduced operational costs by 40%. Built an intuitive Streamlit interface for users to interact with the system. This project demonstrates expertise in LLM application development, vector databases, and production system optimization.</p>
    </div>

    <div class="content-section">
      <h3><i class="fas fa-lightbulb"></i> Key Takeaways</h3>
      <ul style="line-height: 2; color: var(--text-secondary);">
        <li>Chunking strategy significantly impacts retrieval quality and should be domain-specific</li>
        <li>Hybrid search (dense + sparse) outperforms pure vector search for most use cases</li>
        <li>Reranking retrieved chunks improves relevance and reduces hallucination</li>
        <li>Careful prompt engineering is crucial for controlling LLM behavior and output format</li>
        <li>Caching and optimization are essential for cost-effective production LLM applications</li>
        <li>Evaluation benchmarks enable iterative improvement and performance tracking</li>
      </ul>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container">
      <small>© <span id="year"></span> Md Kamrul Hasan — AI Engineer</small>
    </div>
  </footer>

  <script>
    document.getElementById('year').textContent = new Date().getFullYear();
  </script>
</body>
</html>
